{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "import tokenizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanish/Competition/Zindi/Tech4MentalHealth/Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_path' : '../data/train_corrected.csv',\n",
    "          'test_path' : '../data/test_corrected.csv',\n",
    "          'train_batch_size' : 4,\n",
    "          'valid_batch_size' : 8,\n",
    "          'test_batch_size' : 64,\n",
    "          'MAX_LEN' : 196,\n",
    "          'EPOCH' : 3, \n",
    "          'XLNET_PATH_Azure': '/home/thanish/transformer_models/xlnet_base_cased'\n",
    "          }\n",
    "\n",
    "TOKENIZER = transformers.XLNetTokenizer.from_pretrained('xlnet-large-cased', lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dream happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stressed due to lack of financial support...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF = pd.read_csv(config['train_path'])\n",
    "test_DF = pd.read_csv(config['test_path'])\n",
    "\n",
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>BOHSNXCN</td>\n",
       "      <td>what should i do to stop alcoholism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GVDXRQPY</td>\n",
       "      <td>how to become my oneself again</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>IO4JHIQS</td>\n",
       "      <td>how can someone stop it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1DS3P1XO</td>\n",
       "      <td>i feel unworthy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ORF71PVQ</td>\n",
       "      <td>i feel so discouraged with life</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text  Alcohol  \\\n",
       "0    SUAVK39Z            i feel that it was better i dream happy        0   \n",
       "1    9JDAGUV3                        why do i get hallucinations        0   \n",
       "2    419WR1LQ  i am stressed due to lack of financial support...        0   \n",
       "3    6UY7DX6Q                              why is life important        0   \n",
       "4    FYC0FTFB  how could i be helped to go through the depres...        0   \n",
       "..        ...                                                ...      ...   \n",
       "611  BOHSNXCN                what should i do to stop alcoholism        1   \n",
       "612  GVDXRQPY                     how to become my oneself again        0   \n",
       "613  IO4JHIQS                            how can someone stop it        1   \n",
       "614  1DS3P1XO                                    i feel unworthy        0   \n",
       "615  ORF71PVQ                    i feel so discouraged with life        0   \n",
       "\n",
       "     Depression  Drugs  Suicide  \n",
       "0             1      0        0  \n",
       "1             0      1        0  \n",
       "2             1      0        0  \n",
       "3             0      0        1  \n",
       "4             1      0        0  \n",
       "..          ...    ...      ...  \n",
       "611           0      0        0  \n",
       "612           0      0        1  \n",
       "613           0      0        0  \n",
       "614           1      0        0  \n",
       "615           1      0        0  \n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label to OHE\n",
    "train_DF = pd.concat([train_DF[['ID', 'text']], pd.get_dummies(train_DF.label)], axis = 1)\n",
    "train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 6) (124, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_local, valid_local = train_test_split(train_DF,\n",
    "                                            test_size = 0.2,\n",
    "                                            random_state = 100)\n",
    "\n",
    "train_local = train_local.reset_index(drop = True)\n",
    "valid_local = valid_local.reset_index(drop = True)\n",
    "\n",
    "print(train_local.shape, valid_local.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class form_input():\n",
    "    \n",
    "    def __init__(self, text_id, text, label, data_type = 'test'):\n",
    "        self.data_type = data_type\n",
    "        self.text_id = text_id\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.max_len = config['MAX_LEN']\n",
    "        self.tokenizer = TOKENIZER\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  TOKENIZER.encode_plus(self.text[item])\n",
    "        \n",
    "        sub_id = self.text_id[item]\n",
    "        ids = inputs['input_ids']\n",
    "        tok_type_id = inputs['token_type_ids']\n",
    "        att_mask = inputs['attention_mask']\n",
    "        pad_len = self.max_len - len(ids)\n",
    "\n",
    "        ids = ids + [0]*pad_len\n",
    "        tok_type_id = tok_type_id + [0]*pad_len\n",
    "        att_mask = att_mask + [0]*pad_len\n",
    "        \n",
    "        if self.data_type != 'test':\n",
    "            label = self.label[item]\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return {'sub_id': sub_id,\n",
    "                #'Actual_text': self.text[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                'token_type_ids': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'targets': torch.tensor(label, dtype = torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_id': 'BOHSNXCN',\n",
       " 'ids': tensor([  113,   170,    17,   150,   112,    22,   829, 28793,     4,     3,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'targets': tensor([1, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "\n",
    "train_local_data = form_input(train_local.ID, train_local.text, train_local[lab_columns].values, 'train')\n",
    "valid_local_data = form_input(valid_local.ID, valid_local.text, valid_local[lab_columns].values, 'train')\n",
    "train_prod_data = form_input(train_DF.ID, train_DF.text, train_DF[lab_columns].values, 'train')\n",
    "test_prod_data = form_input(test_DF.ID, test_DF.text, None, 'test')\n",
    "\n",
    "train_local_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_data_loader = DataLoader(train_local_data, \n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(train_local_data),\n",
    "                                     batch_size=config['train_batch_size'])\n",
    "valid_local_data_loader = DataLoader(valid_local_data,\n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(valid_local_data),\n",
    "                                     batch_size=config['valid_batch_size'])\n",
    "\n",
    "train_prod_data_loader = DataLoader(train_prod_data, \n",
    "                                    #shuffle=True,\n",
    "                                    sampler = RandomSampler(train_prod_data),\n",
    "                                    batch_size=config['train_batch_size'])\n",
    "\n",
    "test_prod_data_loader = DataLoader(test_prod_data,\n",
    "                                   #shuffle=False,\n",
    "                                   sampler = SequentialSampler(test_prod_data),\n",
    "                                   batch_size=config['test_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLNETMultiLabelSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(XLNETMultiLabelSequenceClassification, self).__init__()\n",
    "        self.freeze_bert = True\n",
    "        self.num_labels = num_labels\n",
    "        self.xlnet = transformers.XLNetModel.from_pretrained(config['XLNET_PATH_Azure'])\n",
    "        self.drop = nn.Dropout(0.2)\n",
    "        self.classifier = torch.nn.Linear(768, self.num_labels)\n",
    "        \n",
    "        freez_parm = ['classifier', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
    "                      '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "        if self.freeze_bert:\n",
    "            for n, param in self.xlnet.named_parameters():\n",
    "                if not any(nd in n for nd in freez_parm):\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        \"Pool the hidden output into a single mean vector\"\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None, labels = None):\n",
    "        # Last layer\n",
    "        last_hidden_state = self.xlnet(input_ids = input_ids, \n",
    "                                       token_type_ids = token_type_ids,\n",
    "                                       attention_mask = attention_mask\n",
    "                                       )\n",
    "        # Pooled the outputs in a mean vector\n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        mean_last_hidden_state = self.drop(mean_last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.view(-1, self.num_labels))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_seed(seed_no = 100):\n",
    "    random.seed(seed_no)\n",
    "    np.random.seed(seed_no)\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed_all(seed_no)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.device_count()>1:\n",
    "#     print(\"It has {} GPUs\".format(torch.cuda.device_count()))\n",
    "    \n",
    "#     setting_seed(seed_no = 50)\n",
    "#     model = XLNETMultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "#     model = nn.DataParallel(model)\n",
    "#     model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_2_tune(model):\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    \n",
    "    return optimizer_grouped_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, scheduler, params):\n",
    "    model.train()\n",
    "\n",
    "    setting_seed(seed_no = seed)\n",
    "    \n",
    "    train_loss  = 0\n",
    "    for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        ids = dataset['ids'].to(device, dtype = torch.long)\n",
    "        mask = dataset['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = dataset['token_type_ids'].to(device, dtype = torch.long)\n",
    "        target = dataset['targets'].to(device, dtype = torch.float)\n",
    "    \n",
    "        output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "        \n",
    "        step_loss = output[0]\n",
    "        prediction = output[1]\n",
    "\n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        torch.nn.utils. clip_grad_norm(model.parameters(), 1.0)\n",
    "        \n",
    "        train_loss += step_loss\n",
    "     \n",
    "    print(\"Saving the model\")\n",
    "    torch.save(model, '../output/best_XLnet_model.bin')\n",
    "    \n",
    "    print(\"Avg Train loss\" , (train_loss/len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    actual_output = []\n",
    "    predicted_output = []\n",
    "    with torch.no_grad():\n",
    "        for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            ids = dataset['ids'].to(device)\n",
    "            token_type_ids = dataset['token_type_ids'].to(device)\n",
    "            mask = dataset['mask'].to(device)\n",
    "            target = dataset['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "            \n",
    "            step_loss = output[0]\n",
    "            prediction = output[1]\n",
    "            \n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        print(\"Avg Eval loss\" , (eval_loss/len(data_loader)))\n",
    "        \n",
    "        return actual_output, predicted_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def training_engine(epoc, train_data):\n",
    "\n",
    "    #seed = 50\n",
    "    \n",
    "    setting_seed(seed_no = seed)\n",
    "    model = XLNETMultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer_grouped_parameters = params_2_tune(model)\n",
    "    optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr = 5e-5)\n",
    "    \n",
    "    EPOCHS = epoc\n",
    "    total_steps = len(train_data) * EPOCHS\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                                             num_warmup_steps=0, # Default value\n",
    "                                                             num_training_steps=total_steps)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Training\n",
    "        train_fn(data_loader = train_data,\n",
    "                 model = model,\n",
    "                 optimizer = optimizer, \n",
    "                 scheduler = scheduler, \n",
    "                 params = optimizer_grouped_parameters)\n",
    "\n",
    "        # Evaluation\n",
    "        actual, predicted = eval_fn(data_loader = valid_local_data_loader,\n",
    "                                    model = model)\n",
    "\n",
    "        actual = np.array(actual)\n",
    "        #predicted_prob = np.array(predicted)\n",
    "        predicted_prob = predicted\n",
    "        predicted_class = np.argmax(np.array(predicted), axis = 1)\n",
    "\n",
    "    #    acc = accuracy_score(actual, predicted_class)\n",
    "        log_ls = log_loss(actual, torch.tensor(predicted_prob).sigmoid())    \n",
    "\n",
    "    #    print(\"Epoch {}/{} Eval Accuracy: {}, Logloss: {}\".format(epoch, EPOCHS, acc, log_ls))\n",
    "        print(\"Epoch {}/{} Logloss: {}\".format(epoch, EPOCHS, log_ls))\n",
    "    return model, actual, predicted_prob, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 50\n",
    "\n",
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 5, train_data = train_local_data_loader)\n",
    "\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [01:15<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n",
      "Avg Train loss tensor([0.4486, 0.4154], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.96it/s]\n",
      "  0%|          | 0/154 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.3172, 0.2508], device='cuda:0')\n",
      "Epoch 0/2 Logloss: 0.6489418936412661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 154/154 [01:15<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n",
      "Avg Train loss tensor([0.2186, 0.1923], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:04<00:00,  3.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.1903, 0.1392], device='cuda:0')\n",
      "Epoch 1/2 Logloss: 0.3571754060244383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]]),\n",
       " array([0, 1, 1, 1, 2, 1, 3, 1, 1, 1, 0, 0, 1, 1, 1, 1, 3, 1, 0, 0, 1, 1,\n",
       "        1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 3, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 3, 0, 1, 1, 3, 3, 0, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 3, 0, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1,\n",
       "        1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 0, 1, 1, 0, 1, 0, 1, 3, 1, 0, 1, 0]),\n",
       " tensor([[9.9667e-01, 3.9841e-04, 7.8399e-03, 3.7860e-03],\n",
       "         [8.3405e-04, 9.9913e-01, 3.3074e-04, 9.3436e-04],\n",
       "         [1.6027e-03, 9.9781e-01, 1.0834e-03, 1.5458e-03],\n",
       "         [3.7114e-04, 9.9918e-01, 4.7455e-04, 2.8959e-03],\n",
       "         [1.7706e-01, 1.1197e-01, 2.0867e-01, 3.8369e-02],\n",
       "         [2.6386e-03, 9.9833e-01, 4.1690e-04, 1.3364e-03],\n",
       "         [7.4570e-03, 5.9598e-01, 2.1692e-02, 8.2315e-01],\n",
       "         [7.8826e-04, 9.9917e-01, 2.9829e-04, 8.6315e-04],\n",
       "         [5.1302e-03, 9.9174e-01, 4.1304e-03, 9.2501e-03],\n",
       "         [9.4635e-03, 6.4862e-01, 2.5992e-02, 4.1506e-01],\n",
       "         [9.9460e-01, 1.2744e-03, 4.4964e-03, 2.1757e-03],\n",
       "         [9.9871e-01, 2.4624e-04, 1.0363e-03, 1.1990e-03],\n",
       "         [1.4022e-03, 9.8818e-01, 4.4147e-03, 7.2015e-02],\n",
       "         [8.3983e-04, 9.9934e-01, 2.9665e-04, 9.3927e-04],\n",
       "         [8.1107e-04, 9.9918e-01, 4.9792e-04, 1.7603e-03],\n",
       "         [2.0246e-03, 9.8173e-01, 1.7814e-03, 5.6114e-02],\n",
       "         [2.0656e-01, 2.2119e-02, 2.7850e-01, 6.7629e-01],\n",
       "         [1.3463e-03, 9.9925e-01, 3.6385e-04, 8.5191e-04],\n",
       "         [7.3898e-01, 1.8781e-03, 5.0152e-01, 4.1642e-02],\n",
       "         [5.4675e-01, 5.7762e-03, 4.8151e-01, 7.2254e-02],\n",
       "         [2.0052e-03, 9.9801e-01, 3.7976e-03, 6.1015e-03],\n",
       "         [1.1391e-03, 9.9563e-01, 1.6728e-03, 4.8500e-03],\n",
       "         [5.6852e-03, 8.0604e-01, 2.7153e-02, 3.8562e-01],\n",
       "         [9.7151e-01, 1.3768e-03, 9.8104e-02, 1.8512e-02],\n",
       "         [3.5770e-01, 1.2761e-02, 5.8286e-01, 1.0169e-01],\n",
       "         [3.3221e-03, 9.9568e-01, 1.3796e-03, 6.1187e-03],\n",
       "         [6.9082e-01, 5.4817e-03, 1.0655e-01, 1.2431e-02],\n",
       "         [9.9982e-01, 1.1297e-04, 8.3973e-04, 3.1729e-04],\n",
       "         [3.7167e-03, 9.7442e-01, 7.9624e-03, 2.0784e-02],\n",
       "         [9.9807e-01, 4.8213e-04, 2.2155e-03, 1.0958e-03],\n",
       "         [7.9101e-04, 9.9910e-01, 5.1516e-04, 1.0681e-03],\n",
       "         [9.9811e-01, 4.1522e-04, 2.6258e-03, 9.5905e-04],\n",
       "         [9.7152e-01, 1.1619e-03, 4.3760e-02, 1.6939e-02],\n",
       "         [1.5567e-03, 9.9289e-01, 3.5991e-03, 3.0453e-02],\n",
       "         [1.1587e-03, 9.9863e-01, 6.3665e-04, 1.6249e-03],\n",
       "         [1.8974e-01, 5.5796e-02, 1.3652e-01, 3.1026e-01],\n",
       "         [5.6280e-01, 1.8343e-02, 4.9695e-01, 1.0758e-01],\n",
       "         [1.4141e-03, 9.9596e-01, 1.2571e-03, 1.2790e-02],\n",
       "         [9.9981e-01, 5.6759e-05, 7.2124e-04, 9.6708e-04],\n",
       "         [6.1572e-03, 9.8260e-01, 4.0575e-03, 4.1083e-02],\n",
       "         [3.7645e-03, 9.9706e-01, 1.9026e-03, 4.1464e-03],\n",
       "         [1.3460e-03, 9.9849e-01, 4.2186e-04, 2.3019e-03],\n",
       "         [8.2004e-03, 8.9499e-01, 1.3908e-02, 7.8651e-02],\n",
       "         [8.0367e-04, 9.9920e-01, 2.7687e-04, 1.2794e-03],\n",
       "         [9.9912e-01, 1.0609e-04, 2.4262e-03, 9.1885e-04],\n",
       "         [2.0030e-03, 9.8212e-01, 5.3059e-03, 2.6519e-02],\n",
       "         [5.0457e-04, 9.9925e-01, 3.6017e-04, 2.6546e-03],\n",
       "         [2.2532e-03, 9.9732e-01, 3.8783e-03, 1.6004e-02],\n",
       "         [3.3429e-03, 9.9528e-01, 1.7945e-03, 5.8682e-03],\n",
       "         [2.3518e-01, 1.6889e-02, 3.0551e-01, 5.8873e-01],\n",
       "         [9.9961e-01, 1.4335e-04, 1.5407e-03, 6.3268e-04],\n",
       "         [2.7750e-02, 5.6957e-01, 1.1989e-02, 2.2585e-01],\n",
       "         [7.5578e-04, 9.9700e-01, 6.3521e-04, 1.0103e-02],\n",
       "         [1.2072e-02, 5.4657e-01, 3.9896e-02, 5.5861e-01],\n",
       "         [1.8261e-02, 3.0044e-01, 3.1203e-02, 6.2577e-01],\n",
       "         [6.0643e-01, 1.5031e-02, 5.5485e-01, 2.4716e-02],\n",
       "         [3.1109e-03, 9.6906e-01, 9.4761e-03, 2.1242e-02],\n",
       "         [9.7146e-04, 9.9922e-01, 9.3581e-04, 2.3116e-03],\n",
       "         [4.3108e-03, 4.5238e-01, 2.0649e-02, 9.4460e-01],\n",
       "         [1.5112e-03, 9.9772e-01, 8.2478e-04, 3.9716e-03],\n",
       "         [9.1814e-04, 9.9938e-01, 3.5990e-04, 1.1348e-03],\n",
       "         [8.6401e-04, 9.9515e-01, 1.1738e-03, 1.6228e-02],\n",
       "         [1.8420e-03, 9.6504e-01, 3.5976e-03, 1.3713e-01],\n",
       "         [1.2159e-03, 9.9669e-01, 1.1131e-03, 3.5053e-03],\n",
       "         [5.6687e-04, 9.9284e-01, 2.4260e-03, 3.5801e-02],\n",
       "         [5.8688e-04, 9.9819e-01, 1.7970e-03, 7.4744e-03],\n",
       "         [9.7151e-01, 1.3768e-03, 9.8104e-02, 1.8512e-02],\n",
       "         [8.1602e-02, 6.9292e-02, 1.7252e-01, 8.4846e-01],\n",
       "         [8.9234e-01, 9.1588e-04, 4.5755e-01, 8.4399e-03],\n",
       "         [1.8939e-03, 9.9229e-01, 4.1861e-03, 6.7808e-02],\n",
       "         [6.5191e-04, 9.9806e-01, 9.3596e-04, 5.5529e-03],\n",
       "         [1.6135e-03, 9.9850e-01, 6.0714e-04, 1.9509e-03],\n",
       "         [8.3405e-04, 9.9913e-01, 3.3074e-04, 9.3436e-04],\n",
       "         [1.6999e-03, 9.9730e-01, 2.9252e-03, 9.4405e-03],\n",
       "         [1.9076e-02, 3.8056e-01, 6.1598e-02, 7.3739e-01],\n",
       "         [7.0025e-04, 9.9958e-01, 4.2766e-04, 9.6960e-04],\n",
       "         [1.7145e-03, 9.9449e-01, 3.3765e-03, 2.0065e-02],\n",
       "         [9.6571e-01, 3.3964e-03, 1.6991e-02, 9.4125e-03],\n",
       "         [9.9871e-01, 1.6417e-04, 2.5536e-03, 3.9897e-03],\n",
       "         [8.6004e-04, 9.9934e-01, 6.4874e-04, 1.2996e-03],\n",
       "         [7.8846e-04, 9.9805e-01, 7.6857e-04, 2.8750e-03],\n",
       "         [9.8085e-01, 8.8797e-04, 7.7000e-03, 1.8260e-02],\n",
       "         [2.8885e-03, 9.6941e-01, 3.5354e-03, 1.3955e-01],\n",
       "         [1.5949e-03, 9.9844e-01, 6.4367e-04, 4.5003e-03],\n",
       "         [6.5577e-01, 6.3465e-03, 2.4810e-01, 2.0645e-01],\n",
       "         [6.8544e-03, 7.5499e-01, 2.7293e-02, 2.9336e-01],\n",
       "         [3.5604e-01, 8.4954e-03, 6.4452e-01, 1.0472e-01],\n",
       "         [1.3156e-03, 9.9882e-01, 8.7637e-04, 4.2678e-03],\n",
       "         [1.2563e-03, 9.9890e-01, 6.4063e-04, 9.1476e-04],\n",
       "         [1.5222e-03, 9.9390e-01, 1.8770e-03, 9.9603e-03],\n",
       "         [1.5665e-03, 9.9796e-01, 8.8703e-04, 2.3799e-03],\n",
       "         [1.2450e-03, 9.9853e-01, 7.1801e-04, 1.5011e-03],\n",
       "         [9.7785e-01, 1.3149e-03, 1.6228e-02, 2.0775e-02],\n",
       "         [1.6545e-02, 4.6210e-01, 4.4885e-02, 3.5750e-01],\n",
       "         [5.8688e-04, 9.9819e-01, 1.7970e-03, 7.4744e-03],\n",
       "         [1.2522e-03, 9.9894e-01, 3.6481e-04, 1.3472e-03],\n",
       "         [9.9849e-01, 2.9728e-04, 1.6949e-03, 1.4324e-03],\n",
       "         [8.9898e-01, 6.4736e-04, 2.3085e-01, 4.2691e-02],\n",
       "         [9.9904e-01, 2.4669e-04, 3.2470e-03, 3.2017e-03],\n",
       "         [1.3630e-03, 9.9890e-01, 3.9232e-04, 1.7790e-03],\n",
       "         [2.5160e-03, 9.9222e-01, 2.1425e-03, 6.1611e-03],\n",
       "         [2.9274e-02, 8.9961e-01, 6.9188e-03, 8.3910e-03],\n",
       "         [6.6006e-03, 9.8961e-01, 4.2531e-03, 2.0605e-02],\n",
       "         [1.8216e-03, 9.9810e-01, 1.0480e-03, 1.3611e-03],\n",
       "         [9.9246e-01, 4.2335e-04, 4.9482e-03, 7.3271e-03],\n",
       "         [1.4488e-02, 7.1562e-01, 9.2880e-03, 3.9227e-01],\n",
       "         [2.7552e-03, 9.9821e-01, 1.1494e-03, 2.4431e-03],\n",
       "         [9.0117e-04, 9.9737e-01, 1.0770e-03, 2.2986e-02],\n",
       "         [8.4480e-04, 9.9914e-01, 5.3206e-04, 2.7277e-03],\n",
       "         [1.0734e-02, 8.6101e-01, 1.7371e-02, 1.8448e-01],\n",
       "         [1.5599e-03, 9.9610e-01, 8.6172e-04, 7.0771e-03],\n",
       "         [9.9659e-01, 4.9297e-04, 1.6562e-03, 1.6884e-03],\n",
       "         [9.9864e-01, 1.6493e-04, 4.1104e-03, 8.7002e-04],\n",
       "         [1.9148e-02, 4.7739e-01, 1.6644e-02, 2.9420e-01],\n",
       "         [2.1320e-03, 9.9577e-01, 1.2627e-03, 6.9139e-03],\n",
       "         [9.9968e-01, 2.0230e-04, 7.4216e-04, 6.1444e-04],\n",
       "         [3.2411e-02, 6.9522e-01, 3.0671e-02, 1.6705e-01],\n",
       "         [9.9922e-01, 2.2377e-04, 3.4236e-04, 9.6410e-04],\n",
       "         [1.3146e-03, 9.9813e-01, 5.8333e-04, 2.7102e-03],\n",
       "         [1.9839e-02, 3.8064e-01, 4.6182e-02, 6.2372e-01],\n",
       "         [1.4260e-03, 9.8796e-01, 1.1534e-03, 2.2841e-02],\n",
       "         [9.8783e-01, 2.3764e-03, 1.0304e-02, 2.3463e-03],\n",
       "         [1.6019e-03, 9.9529e-01, 3.4826e-03, 1.7154e-02],\n",
       "         [9.9870e-01, 4.2128e-04, 2.0086e-03, 8.5911e-04]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 2, train_data = train_prod_data_loader)\n",
    "\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('../output/best_XLnet_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "submission_ID = []\n",
    "with torch.no_grad():\n",
    "    for index, dataset in tqdm(enumerate(test_prod_data_loader), total = len(test_prod_data_loader)):\n",
    "        sub_id = dataset['sub_id']\n",
    "        ids = dataset['ids'].to(device)\n",
    "        #token_type_ids = dataset['token_type_ids'].to(device)\n",
    "        mask = dataset['mask'].to(device)\n",
    "\n",
    "        output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask)\n",
    "        \n",
    "        submission_ID.extend(sub_id)\n",
    "        predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())\n",
    "    predicted_output = np.array(predicted_output)\n",
    "            \n",
    "        #predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.984825</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.022060</td>\n",
       "      <td>0.002483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.998472</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.000452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.997337</td>\n",
       "      <td>0.002758</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.001869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>0.997436</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.003053</td>\n",
       "      <td>0.000780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>0.092169</td>\n",
       "      <td>0.531902</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.040550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Z9A6ACLK</td>\n",
       "      <td>0.995849</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.001412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ZDUOIGKN</td>\n",
       "      <td>0.997849</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.010419</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ZHQ60CCH</td>\n",
       "      <td>0.658384</td>\n",
       "      <td>0.020317</td>\n",
       "      <td>0.568046</td>\n",
       "      <td>0.014261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ZVIJMA4O</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.651517</td>\n",
       "      <td>0.056192</td>\n",
       "      <td>0.344829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ZYIFAY98</td>\n",
       "      <td>0.188965</td>\n",
       "      <td>0.111732</td>\n",
       "      <td>0.215344</td>\n",
       "      <td>0.114868</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Depression   Alcohol   Suicide     Drugs\n",
       "0    02V56KMO    0.984825  0.002539  0.022060  0.002483\n",
       "1    03BMGTOK    0.998472  0.001058  0.002150  0.000452\n",
       "2    03LZVFM6    0.997337  0.002758  0.003937  0.001869\n",
       "3    0EPULUM5    0.997436  0.001118  0.003053  0.000780\n",
       "4    0GM4C5GD    0.092169  0.531902  0.018045  0.040550\n",
       "..        ...         ...       ...       ...       ...\n",
       "304  Z9A6ACLK    0.995849  0.002250  0.003045  0.001412\n",
       "305  ZDUOIGKN    0.997849  0.000799  0.010419  0.000308\n",
       "306  ZHQ60CCH    0.658384  0.020317  0.568046  0.014261\n",
       "307  ZVIJMA4O    0.008752  0.651517  0.056192  0.344829\n",
       "308  ZYIFAY98    0.188965  0.111732  0.215344  0.114868\n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.DataFrame(predicted_output)\n",
    "final_output.columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "final_output['ID'] = submission_ID\n",
    "\n",
    "final_output = final_output[['ID', 'Depression', 'Alcohol', 'Suicide', 'Drugs']]\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('../output/sub_45_XLnet.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
