{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "import tokenizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ANT.AMAZON.COM/thanisb/Competition/Zindi/Tech4MentalHealth/Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_path' : '../data/train_corrected.csv',\n",
    "          'test_path' : '../data/test_corrected.csv',\n",
    "          'train_batch_size' : 4,\n",
    "          'valid_batch_size' : 4,\n",
    "          'test_batch_size' : 64,\n",
    "          'MAX_LEN' : 196,\n",
    "          'EPOCH' : 3, \n",
    "          'XLM_Roberta_base_PATH_Azure': '/home/thanish/transformer_models/XLM_Roberta_base',\n",
    "          'XLM_Roberta_base_PATH_off_desktop': '/home/ANT.AMAZON.COM/thanisb/transformer_models/XLM_Roberta_base'\n",
    "          }\n",
    "\n",
    "TOKENIZER = transformers.XLMRobertaTokenizer(vocab_file = os.path.join(config['XLM_Roberta_base_PATH_off_desktop'], \n",
    "                                                                       'sentencepiece.bpe.model'),\n",
    "                                             lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dream happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stressed due to lack of financial support...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF = pd.read_csv(config['train_path'])\n",
    "test_DF = pd.read_csv(config['test_path'])\n",
    "\n",
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>BOHSNXCN</td>\n",
       "      <td>what should i do to stop alcoholism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GVDXRQPY</td>\n",
       "      <td>how to become my oneself again</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>IO4JHIQS</td>\n",
       "      <td>how can someone stop it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1DS3P1XO</td>\n",
       "      <td>i feel unworthy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ORF71PVQ</td>\n",
       "      <td>i feel so discouraged with life</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text  Alcohol  \\\n",
       "0    SUAVK39Z            i feel that it was better i dream happy        0   \n",
       "1    9JDAGUV3                        why do i get hallucinations        0   \n",
       "2    419WR1LQ  i am stressed due to lack of financial support...        0   \n",
       "3    6UY7DX6Q                              why is life important        0   \n",
       "4    FYC0FTFB  how could i be helped to go through the depres...        0   \n",
       "..        ...                                                ...      ...   \n",
       "611  BOHSNXCN                what should i do to stop alcoholism        1   \n",
       "612  GVDXRQPY                     how to become my oneself again        0   \n",
       "613  IO4JHIQS                            how can someone stop it        1   \n",
       "614  1DS3P1XO                                    i feel unworthy        0   \n",
       "615  ORF71PVQ                    i feel so discouraged with life        0   \n",
       "\n",
       "     Depression  Drugs  Suicide  \n",
       "0             1      0        0  \n",
       "1             0      1        0  \n",
       "2             1      0        0  \n",
       "3             0      0        1  \n",
       "4             1      0        0  \n",
       "..          ...    ...      ...  \n",
       "611           0      0        0  \n",
       "612           0      0        1  \n",
       "613           0      0        0  \n",
       "614           1      0        0  \n",
       "615           1      0        0  \n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label to OHE\n",
    "train_DF = pd.concat([train_DF[['ID', 'text']], pd.get_dummies(train_DF.label)], axis = 1)\n",
    "train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 6) (124, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_local, valid_local = train_test_split(train_DF,\n",
    "                                            test_size = 0.2,\n",
    "                                            random_state = 100)\n",
    "\n",
    "train_local = train_local.reset_index(drop = True)\n",
    "valid_local = valid_local.reset_index(drop = True)\n",
    "\n",
    "print(train_local.shape, valid_local.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class form_input():\n",
    "    \n",
    "    def __init__(self, text_id, text, label, data_type = 'test'):\n",
    "        self.data_type = data_type\n",
    "        self.text_id = text_id\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.max_len = config['MAX_LEN']\n",
    "        self.tokenizer = TOKENIZER\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  TOKENIZER.encode_plus(self.text[item])\n",
    "        \n",
    "        sub_id = self.text_id[item]\n",
    "        ids = inputs['input_ids']\n",
    "        #tok_type_id = inputs['token_type_ids']\n",
    "        att_mask = inputs['attention_mask']\n",
    "        pad_len = self.max_len - len(ids)\n",
    "\n",
    "        ids = ids + [0]*pad_len\n",
    "        #tok_type_id = tok_type_id + [0]*pad_len\n",
    "        att_mask = att_mask + [0]*pad_len\n",
    "        \n",
    "        if self.data_type != 'test':\n",
    "            label = self.label[item]\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return {'sub_id': sub_id,\n",
    "                #'Actual_text': self.text[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                #'token_type_ids': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'targets': torch.tensor(label, dtype = torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': tensor([    0,  2367,  5608,    17,    54,    47,  7279, 57913,  8780,     2,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'sub_id': 'BOHSNXCN',\n",
       " 'targets': tensor([1, 0, 0, 0])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "\n",
    "train_local_data = form_input(train_local.ID, train_local.text, train_local[lab_columns].values, 'train')\n",
    "valid_local_data = form_input(valid_local.ID, valid_local.text, valid_local[lab_columns].values, 'train')\n",
    "train_prod_data = form_input(train_DF.ID, train_DF.text, train_DF[lab_columns].values, 'train')\n",
    "test_prod_data = form_input(test_DF.ID, test_DF.text, None, 'test')\n",
    "\n",
    "train_local_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_data_loader = DataLoader(train_local_data, \n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(train_local_data),\n",
    "                                     batch_size=config['train_batch_size'])\n",
    "valid_local_data_loader = DataLoader(valid_local_data,\n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(valid_local_data),\n",
    "                                     batch_size=config['valid_batch_size'])\n",
    "\n",
    "train_prod_data_loader = DataLoader(train_prod_data, \n",
    "                                    #shuffle=True,\n",
    "                                    sampler = RandomSampler(train_prod_data),\n",
    "                                    batch_size=config['train_batch_size'])\n",
    "\n",
    "test_prod_data_loader = DataLoader(test_prod_data,\n",
    "                                   #shuffle=False,\n",
    "                                   sampler = SequentialSampler(test_prod_data),\n",
    "                                   batch_size=config['test_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLM_Roberta_base_MultiLabelSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(XLM_Roberta_base_MultiLabelSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.freeze_bert = False\n",
    "        self.XLM_Roberta_base = transformers.XLMRobertaModel.from_pretrained(config['XLM_Roberta_base_PATH_off_desktop'])\n",
    "        self.classifier = torch.nn.Linear(768, self.num_labels)\n",
    "        \n",
    "        freez_parm = ['classifier', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
    "                      '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "        if self.freeze_bert:\n",
    "            # for param in self.Bert_large.parameters():\n",
    "            for n, param in self.Bert_large.named_parameters():\n",
    "                if not any(nd in n for nd in freez_parm):\n",
    "                    param.requires_grad = False\n",
    "                    \n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        \"Pool the hidden output into a single mean vector\"\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None, labels = None):\n",
    "        # Last layer\n",
    "        last_hidden_state = self.XLM_Roberta_base(input_ids = input_ids, \n",
    "                                                   #token_type_ids = token_type_ids,\n",
    "                                                   attention_mask = attention_mask\n",
    "                                       )\n",
    "        # Pooled the outputs in a mean vector\n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.view(-1, self.num_labels))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_seed(seed_no = 100):\n",
    "    random.seed(seed_no)\n",
    "    np.random.seed(seed_no)\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed_all(seed_no)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_2_tune(model):\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "    \n",
    "    return optimizer_grouped_parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, scheduler, params):\n",
    "    model.train()\n",
    "\n",
    "    setting_seed(seed_no = seed)\n",
    "    \n",
    "    train_loss  = 0\n",
    "    for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        ids = dataset['ids'].to(device, dtype = torch.long)\n",
    "        mask = dataset['mask'].to(device, dtype = torch.long)\n",
    "        #token_type_ids = dataset['token_type_ids'].to(device, dtype = torch.long)\n",
    "        target = dataset['targets'].to(device, dtype = torch.float)\n",
    "    \n",
    "        output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "        \n",
    "        step_loss = output[0]\n",
    "        prediction = output[1]\n",
    "\n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        torch.nn.utils. clip_grad_norm(model.parameters(), 1.0)\n",
    "        \n",
    "        train_loss += step_loss\n",
    "     \n",
    "    print(\"Saving the model\")\n",
    "    torch.save(model, '../output/best_XLM_Roberta_base_model.bin')\n",
    "    \n",
    "    print(\"Avg Train loss\" , (train_loss/len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    actual_output = []\n",
    "    predicted_output = []\n",
    "    with torch.no_grad():\n",
    "        for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            ids = dataset['ids'].to(device)\n",
    "            token_type_ids = dataset['token_type_ids'].to(device)\n",
    "            mask = dataset['mask'].to(device)\n",
    "            target = dataset['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output = model(input_ids = ids,\n",
    "                           token_type_ids = token_type_ids,\n",
    "                           attention_mask = mask,\n",
    "                           labels = target\n",
    "                      )\n",
    "            \n",
    "            step_loss = output[0]\n",
    "            prediction = output[1]\n",
    "            \n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        print(\"Avg Eval loss\" , (eval_loss/len(data_loader)))\n",
    "        \n",
    "        return actual_output, predicted_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_engine(epoc, train_data):\n",
    "\n",
    "    #seed = 50\n",
    "    \n",
    "    setting_seed(seed_no = seed)\n",
    "    model = XLM_Roberta_base_MultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer_grouped_parameters = params_2_tune(model)\n",
    "    optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr = 5e-5)\n",
    "    \n",
    "    EPOCHS = epoc\n",
    "    total_steps = len(train_data) * EPOCHS\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                                             num_warmup_steps=0, # Default value\n",
    "                                                             num_training_steps=total_steps)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        # Training\n",
    "        train_fn(data_loader = train_data,\n",
    "                 model = model,\n",
    "                 optimizer = optimizer, \n",
    "                 scheduler = scheduler, \n",
    "                 params = optimizer_grouped_parameters)\n",
    "\n",
    "        # Evaluation\n",
    "        actual, predicted = eval_fn(data_loader = valid_local_data_loader,\n",
    "                                    model = model)\n",
    "\n",
    "        actual = np.array(actual)\n",
    "        #predicted_prob = np.array(predicted)\n",
    "        predicted_prob = predicted\n",
    "        predicted_class = np.argmax(np.array(predicted), axis = 1)\n",
    "\n",
    "    #    acc = accuracy_score(actual, predicted_class)\n",
    "        log_ls = log_loss(actual, torch.tensor(predicted_prob).sigmoid())    \n",
    "\n",
    "    #    print(\"Epoch {}/{} Eval Accuracy: {}, Logloss: {}\".format(epoch, EPOCHS, acc, log_ls))\n",
    "        print(\"Epoch {}/{} Logloss: {}\".format(epoch, EPOCHS, log_ls))\n",
    "    return model, actual, predicted_prob, predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|â–ˆâ–‹        | 21/123 [12:08<2:24:09, 84.80s/it] "
     ]
    }
   ],
   "source": [
    "seed = 50\n",
    "\n",
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 5, train_data = train_local_data_loader)\n",
    "\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 2, train_data = train_prod_data_loader)\n",
    "\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "submission_ID = []\n",
    "with torch.no_grad():\n",
    "    for index, dataset in tqdm(enumerate(test_prod_data_loader), total = len(test_prod_data_loader)):\n",
    "        sub_id = dataset['sub_id']\n",
    "        ids = dataset['ids'].to(device)\n",
    "        #token_type_ids = dataset['token_type_ids'].to(device)\n",
    "        mask = dataset['mask'].to(device)\n",
    "\n",
    "        output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask)\n",
    "        \n",
    "        submission_ID.extend(sub_id)\n",
    "        predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())\n",
    "    predicted_output = np.array(predicted_output)\n",
    "            \n",
    "        #predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.011118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.987378</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.987523</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>0.983092</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.682546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Z9A6ACLK</td>\n",
       "      <td>0.918719</td>\n",
       "      <td>0.023373</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.009388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ZDUOIGKN</td>\n",
       "      <td>0.626443</td>\n",
       "      <td>0.073533</td>\n",
       "      <td>0.152156</td>\n",
       "      <td>0.025714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ZHQ60CCH</td>\n",
       "      <td>0.438941</td>\n",
       "      <td>0.273319</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>0.066414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ZVIJMA4O</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.058782</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.955454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ZYIFAY98</td>\n",
       "      <td>0.557877</td>\n",
       "      <td>0.212203</td>\n",
       "      <td>0.102656</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Depression   Alcohol   Suicide     Drugs\n",
       "0    02V56KMO    0.931522  0.024450  0.038067  0.011118\n",
       "1    03BMGTOK    0.987378  0.005538  0.009145  0.004602\n",
       "2    03LZVFM6    0.987523  0.007561  0.008126  0.004713\n",
       "3    0EPULUM5    0.983092  0.006485  0.012617  0.002972\n",
       "4    0GM4C5GD    0.014191  0.386111  0.008929  0.682546\n",
       "..        ...         ...       ...       ...       ...\n",
       "304  Z9A6ACLK    0.918719  0.023373  0.011878  0.009388\n",
       "305  ZDUOIGKN    0.626443  0.073533  0.152156  0.025714\n",
       "306  ZHQ60CCH    0.438941  0.273319  0.232021  0.066414\n",
       "307  ZVIJMA4O    0.022413  0.058782  0.014278  0.955454\n",
       "308  ZYIFAY98    0.557877  0.212203  0.102656  0.035717\n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.DataFrame(predicted_output)\n",
    "final_output.columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "final_output['ID'] = submission_ID\n",
    "\n",
    "final_output = final_output[['ID', 'Depression', 'Alcohol', 'Suicide', 'Drugs']]\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('../output/sub_Roberta_26.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
