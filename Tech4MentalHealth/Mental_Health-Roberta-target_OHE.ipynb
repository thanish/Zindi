{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "import tokenizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanish/Competition/Zindi/Tech4MentalHealth/Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_path' : '../data/train_corrected.csv',\n",
    "          'test_path' : '../data/test_corrected.csv',\n",
    "          'train_batch_size' : 8,\n",
    "          'valid_batch_size' : 8,\n",
    "          'test_batch_size' : 64,\n",
    "          'MAX_LEN' : 196,\n",
    "          'EPOCH' : 3, \n",
    "          'Roberta_PATH_Azure': '/home/thanish/transformer_models/roberta_base'\n",
    "          }\n",
    "\n",
    "TOKENIZER = transformers.RobertaTokenizer(vocab_file = os.path.join(config['Roberta_PATH_Azure'], 'vocab.json'), \n",
    "                                          merges_file = os.path.join(config['Roberta_PATH_Azure'], 'merges.txt'),\n",
    "                                          lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dream happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stressed due to lack of financial support...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF = pd.read_csv(config['train_path'])\n",
    "test_DF = pd.read_csv(config['test_path'])\n",
    "\n",
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>BOHSNXCN</td>\n",
       "      <td>what should i do to stop alcoholism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GVDXRQPY</td>\n",
       "      <td>how to become my oneself again</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>IO4JHIQS</td>\n",
       "      <td>how can someone stop it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1DS3P1XO</td>\n",
       "      <td>i feel unworthy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ORF71PVQ</td>\n",
       "      <td>i feel so discouraged with life</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text  Alcohol  \\\n",
       "0    SUAVK39Z            i feel that it was better i dream happy        0   \n",
       "1    9JDAGUV3                        why do i get hallucinations        0   \n",
       "2    419WR1LQ  i am stressed due to lack of financial support...        0   \n",
       "3    6UY7DX6Q                              why is life important        0   \n",
       "4    FYC0FTFB  how could i be helped to go through the depres...        0   \n",
       "..        ...                                                ...      ...   \n",
       "611  BOHSNXCN                what should i do to stop alcoholism        1   \n",
       "612  GVDXRQPY                     how to become my oneself again        0   \n",
       "613  IO4JHIQS                            how can someone stop it        1   \n",
       "614  1DS3P1XO                                    i feel unworthy        0   \n",
       "615  ORF71PVQ                    i feel so discouraged with life        0   \n",
       "\n",
       "     Depression  Drugs  Suicide  \n",
       "0             1      0        0  \n",
       "1             0      1        0  \n",
       "2             1      0        0  \n",
       "3             0      0        1  \n",
       "4             1      0        0  \n",
       "..          ...    ...      ...  \n",
       "611           0      0        0  \n",
       "612           0      0        1  \n",
       "613           0      0        0  \n",
       "614           1      0        0  \n",
       "615           1      0        0  \n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label to OHE\n",
    "train_DF = pd.concat([train_DF[['ID', 'text']], pd.get_dummies(train_DF.label)], axis = 1)\n",
    "train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 6) (124, 6)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "train_local, valid_local = train_test_split(train_DF,\n",
    "                                            test_size = 0.2,\n",
    "                                            random_state = 100)\n",
    "\n",
    "train_local = train_local.reset_index(drop = True)\n",
    "valid_local = valid_local.reset_index(drop = True)\n",
    "\n",
    "print(train_local.shape, valid_local.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class form_input():\n",
    "    \n",
    "    def __init__(self, text_id, text, label, data_type = 'test'):\n",
    "        self.data_type = data_type\n",
    "        self.text_id = text_id\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.max_len = config['MAX_LEN']\n",
    "        self.tokenizer = TOKENIZER\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  TOKENIZER.encode_plus(self.text[item])\n",
    "        \n",
    "        sub_id = self.text_id[item]\n",
    "        ids = inputs['input_ids']\n",
    "        #tok_type_id = inputs['token_type_ids']\n",
    "        att_mask = inputs['attention_mask']\n",
    "        pad_len = self.max_len - len(ids)\n",
    "\n",
    "        ids = ids + [0]*pad_len\n",
    "        #tok_type_id = tok_type_id + [0]*pad_len\n",
    "        att_mask = att_mask + [0]*pad_len\n",
    "        \n",
    "        if self.data_type != 'test':\n",
    "            label = self.label[item]\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return {'sub_id': sub_id,\n",
    "                #'Actual_text': self.text[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                #'token_type_ids': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'targets': torch.tensor(label, dtype = torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_id': 'BOHSNXCN',\n",
       " 'ids': tensor([    0,    99,   197,   939,   109,     7,   912, 37934,     2,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'targets': tensor([1, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "\n",
    "train_local_data = form_input(train_local.ID, train_local.text, train_local[lab_columns].values, 'train')\n",
    "valid_local_data = form_input(valid_local.ID, valid_local.text, valid_local[lab_columns].values, 'train')\n",
    "train_prod_data = form_input(train_DF.ID, train_DF.text, train_DF[lab_columns].values, 'train')\n",
    "test_prod_data = form_input(test_DF.ID, test_DF.text, None, 'test')\n",
    "\n",
    "train_local_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_data_loader = DataLoader(train_local_data, \n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(train_local_data),\n",
    "                                     batch_size=config['train_batch_size'])\n",
    "valid_local_data_loader = DataLoader(valid_local_data,\n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(valid_local_data),\n",
    "                                     batch_size=config['valid_batch_size'])\n",
    "\n",
    "train_prod_data_loader = DataLoader(train_prod_data, \n",
    "                                    #shuffle=True,\n",
    "                                    sampler = RandomSampler(train_prod_data),\n",
    "                                    batch_size=config['train_batch_size'])\n",
    "\n",
    "test_prod_data_loader = DataLoader(test_prod_data,\n",
    "                                   #shuffle=False,\n",
    "                                   sampler = SequentialSampler(test_prod_data),\n",
    "                                   batch_size=config['test_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaMultiLabelSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(RobertaMultiLabelSequenceClassification, self).__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.Roberta = transformers.RobertaModel.from_pretrained(config['Roberta_PATH_Azure'])\n",
    "        self.classifier = torch.nn.Linear(768, self.num_labels)\n",
    "        \n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        \"Pool the hidden output into a single mean vector\"\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None, labels = None):\n",
    "        # Last layer\n",
    "        last_hidden_state = self.Roberta(input_ids = input_ids, \n",
    "                                         #token_type_ids = token_type_ids,\n",
    "                                         attention_mask = attention_mask\n",
    "                                       )\n",
    "        # Pooled the outputs in a mean vector\n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.view(-1, self.num_labels))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It has 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.device_count()>1:\n",
    "    print(\"It has {} GPUs\".format(torch.cuda.device_count()))\n",
    "    model = RobertaMultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss  = 0\n",
    "    for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        ids = dataset['ids'].to(device, dtype = torch.long)\n",
    "        mask = dataset['mask'].to(device, dtype = torch.long)\n",
    "        #token_type_ids = dataset['token_type_ids'].to(device, dtype = torch.long)\n",
    "        target = dataset['targets'].to(device, dtype = torch.float)\n",
    "    \n",
    "        output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "        \n",
    "        step_loss = output[0]\n",
    "        prediction = output[1]\n",
    "\n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        train_loss += step_loss\n",
    "        \n",
    "    print('Saving the model')\n",
    "    torch.save(model, '../output/best_Roberta_model.bin')\n",
    "        \n",
    "    print(\"Avg Train loss\" , (train_loss/len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    actual_output = []\n",
    "    predicted_output = []\n",
    "    with torch.no_grad():\n",
    "        for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            ids = dataset['ids'].to(device)\n",
    "            #token_type_ids = dataset['token_type_ids'].to(device)\n",
    "            mask = dataset['mask'].to(device)\n",
    "            target = dataset['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "            \n",
    "            step_loss = output[0]\n",
    "            prediction = output[1]\n",
    "            \n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        print(\"Avg Eval loss\" , (eval_loss/len(data_loader)))\n",
    "        \n",
    "        return actual_output, predicted_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:45<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.3666, 0.3628], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.80it/s]\n",
      "  0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.2119, 0.1499], device='cuda:0')\n",
      "Epoch 0/2 Logloss: 0.36401699288117306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [00:44<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.1680, 0.1735], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:03<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.0842, 0.1174], device='cuda:0')\n",
      "Epoch 1/2 Logloss: 0.23771459600257297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    # Training\n",
    "    train_fn(data_loader = train_prod_data_loader,\n",
    "             model = model,\n",
    "             optimizer = optimizer)\n",
    "    \n",
    "    # Evaluation\n",
    "    actual, predicted = eval_fn(data_loader = valid_local_data_loader,\n",
    "                                model = model)\n",
    "\n",
    "    actual = np.array(actual)\n",
    "    #predicted_prob = np.array(predicted)\n",
    "    predicted_prob = predicted\n",
    "    predicted_class = np.argmax(np.array(predicted), axis = 1)\n",
    "\n",
    "#    acc = accuracy_score(actual, predicted_class)\n",
    "    log_ls = log_loss(actual, torch.tensor(predicted_prob).sigmoid())    \n",
    "    \n",
    "#    print(\"Epoch {}/{} Eval Accuracy: {}, Logloss: {}\".format(epoch, EPOCHS, acc, log_ls))\n",
    "    print(\"Epoch {}/{} Logloss: {}\".format(epoch, EPOCHS, log_ls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.]]),\n",
       " array([1, 1, 2, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 3, 3, 1, 0, 0, 1, 1, 0,\n",
       "        1, 0, 1, 3, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 0, 1, 1, 2, 1,\n",
       "        1, 0, 1, 1, 1, 0, 0, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1, 1, 1, 2, 0, 2,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 2]),\n",
       " tensor([[0.0535, 0.7880, 0.0108, 0.1981],\n",
       "         [0.0084, 0.9882, 0.0045, 0.0076],\n",
       "         [0.0977, 0.0200, 0.9784, 0.0139],\n",
       "         [0.9932, 0.0188, 0.0113, 0.0090],\n",
       "         [0.9941, 0.0196, 0.0105, 0.0088],\n",
       "         [0.0057, 0.9880, 0.0034, 0.0101],\n",
       "         [0.0355, 0.9116, 0.0232, 0.0497],\n",
       "         [0.0111, 0.9862, 0.0066, 0.0098],\n",
       "         [0.0061, 0.9857, 0.0029, 0.0110],\n",
       "         [0.9932, 0.0176, 0.0109, 0.0082],\n",
       "         [0.0079, 0.9781, 0.0040, 0.0115],\n",
       "         [0.0067, 0.9848, 0.0033, 0.0103],\n",
       "         [0.9881, 0.0135, 0.0135, 0.0064],\n",
       "         [0.0585, 0.8127, 0.0140, 0.0420],\n",
       "         [0.0763, 0.2807, 0.0142, 0.6552],\n",
       "         [0.0294, 0.0694, 0.0162, 0.9323],\n",
       "         [0.1297, 0.6598, 0.0247, 0.2570],\n",
       "         [0.9827, 0.0187, 0.0210, 0.0059],\n",
       "         [0.9911, 0.0195, 0.0131, 0.0071],\n",
       "         [0.0108, 0.9864, 0.0069, 0.0094],\n",
       "         [0.0120, 0.9859, 0.0076, 0.0104],\n",
       "         [0.9942, 0.0187, 0.0092, 0.0092],\n",
       "         [0.0113, 0.9870, 0.0059, 0.0096],\n",
       "         [0.9623, 0.0128, 0.0556, 0.0060],\n",
       "         [0.1407, 0.6189, 0.0602, 0.2226],\n",
       "         [0.0336, 0.0695, 0.0236, 0.9508],\n",
       "         [0.0109, 0.9748, 0.0047, 0.0115],\n",
       "         [0.0052, 0.9845, 0.0054, 0.0084],\n",
       "         [0.0097, 0.9699, 0.0092, 0.0122],\n",
       "         [0.9858, 0.0189, 0.0125, 0.0054],\n",
       "         [0.1058, 0.4849, 0.0253, 0.2724],\n",
       "         [0.9844, 0.0200, 0.0316, 0.0069],\n",
       "         [0.0061, 0.9891, 0.0034, 0.0096],\n",
       "         [0.3684, 0.1972, 0.0295, 0.2081],\n",
       "         [0.0079, 0.9804, 0.0055, 0.0091],\n",
       "         [0.0130, 0.9597, 0.0091, 0.0085],\n",
       "         [0.0073, 0.9885, 0.0036, 0.0092],\n",
       "         [0.9881, 0.0178, 0.0210, 0.0069],\n",
       "         [0.1722, 0.5958, 0.0688, 0.3038],\n",
       "         [0.0789, 0.1643, 0.6888, 0.0977],\n",
       "         [0.0723, 0.0181, 0.9754, 0.0138],\n",
       "         [0.3988, 0.2036, 0.0368, 0.0172],\n",
       "         [0.0071, 0.9847, 0.0041, 0.0172],\n",
       "         [0.0067, 0.9877, 0.0042, 0.0097],\n",
       "         [0.0069, 0.9893, 0.0035, 0.0098],\n",
       "         [0.0128, 0.9743, 0.0077, 0.0086],\n",
       "         [0.0641, 0.7445, 0.0405, 0.0443],\n",
       "         [0.0124, 0.9649, 0.0029, 0.0419],\n",
       "         [0.0153, 0.9786, 0.0036, 0.0171],\n",
       "         [0.0105, 0.9764, 0.0022, 0.0182],\n",
       "         [0.9912, 0.0184, 0.0101, 0.0086],\n",
       "         [0.0119, 0.9864, 0.0057, 0.0098],\n",
       "         [0.2788, 0.3392, 0.0454, 0.3195],\n",
       "         [0.0126, 0.9863, 0.0075, 0.0117],\n",
       "         [0.0063, 0.9811, 0.0040, 0.0208],\n",
       "         [0.2151, 0.4037, 0.0854, 0.3135],\n",
       "         [0.0382, 0.0662, 0.0225, 0.9431],\n",
       "         [0.9933, 0.0180, 0.0119, 0.0108],\n",
       "         [0.0175, 0.8972, 0.0173, 0.0194],\n",
       "         [0.0069, 0.9888, 0.0034, 0.0099],\n",
       "         [0.0063, 0.9775, 0.0123, 0.0110],\n",
       "         [0.0162, 0.9451, 0.0136, 0.0200],\n",
       "         [0.0138, 0.9435, 0.0082, 0.0633],\n",
       "         [0.0056, 0.9859, 0.0035, 0.0121],\n",
       "         [0.1272, 0.7518, 0.0421, 0.1017],\n",
       "         [0.0067, 0.9848, 0.0033, 0.0103],\n",
       "         [0.1468, 0.0167, 0.9717, 0.0201],\n",
       "         [0.0073, 0.9861, 0.0047, 0.0108],\n",
       "         [0.0221, 0.9089, 0.0135, 0.0227],\n",
       "         [0.0235, 0.8827, 0.0278, 0.0298],\n",
       "         [0.0119, 0.9855, 0.0058, 0.0086],\n",
       "         [0.0236, 0.9425, 0.0052, 0.0818],\n",
       "         [0.0104, 0.9875, 0.0047, 0.0099],\n",
       "         [0.0076, 0.9830, 0.0024, 0.0222],\n",
       "         [0.0349, 0.6759, 0.0285, 0.1788],\n",
       "         [0.2312, 0.0173, 0.9481, 0.0097],\n",
       "         [0.1680, 0.5075, 0.0571, 0.2321],\n",
       "         [0.1450, 0.5566, 0.0341, 0.2606],\n",
       "         [0.0747, 0.8504, 0.0265, 0.0769],\n",
       "         [0.1268, 0.7198, 0.0552, 0.0610],\n",
       "         [0.0062, 0.9895, 0.0035, 0.0133],\n",
       "         [0.0374, 0.0666, 0.0151, 0.9394],\n",
       "         [0.0061, 0.9833, 0.0042, 0.0147],\n",
       "         [0.9929, 0.0197, 0.0105, 0.0095],\n",
       "         [0.0096, 0.9850, 0.0077, 0.0089],\n",
       "         [0.0056, 0.9849, 0.0031, 0.0116],\n",
       "         [0.0702, 0.0200, 0.9754, 0.0103],\n",
       "         [0.0193, 0.9558, 0.0052, 0.0478],\n",
       "         [0.0060, 0.9868, 0.0030, 0.0113],\n",
       "         [0.3874, 0.0562, 0.3872, 0.0152],\n",
       "         [0.1200, 0.5175, 0.0794, 0.1566],\n",
       "         [0.1964, 0.5787, 0.1255, 0.1671],\n",
       "         [0.0088, 0.9814, 0.0034, 0.0229],\n",
       "         [0.9940, 0.0171, 0.0096, 0.0092],\n",
       "         [0.9938, 0.0185, 0.0091, 0.0087],\n",
       "         [0.0108, 0.9874, 0.0049, 0.0102],\n",
       "         [0.9936, 0.0207, 0.0089, 0.0100],\n",
       "         [0.0349, 0.0501, 0.9341, 0.0158],\n",
       "         [0.9917, 0.0171, 0.0135, 0.0073],\n",
       "         [0.0092, 0.9761, 0.0104, 0.0162],\n",
       "         [0.0078, 0.9881, 0.0041, 0.0082],\n",
       "         [0.9929, 0.0197, 0.0123, 0.0094],\n",
       "         [0.0561, 0.0296, 0.9555, 0.0242],\n",
       "         [0.1843, 0.4910, 0.0854, 0.2537],\n",
       "         [0.0281, 0.9214, 0.0090, 0.0386],\n",
       "         [0.0108, 0.9864, 0.0069, 0.0094],\n",
       "         [0.0058, 0.9662, 0.0039, 0.0251],\n",
       "         [0.0900, 0.0162, 0.9789, 0.0128],\n",
       "         [0.9935, 0.0202, 0.0091, 0.0088],\n",
       "         [0.0705, 0.0169, 0.9825, 0.0156],\n",
       "         [0.9844, 0.0200, 0.0316, 0.0069],\n",
       "         [0.0172, 0.9553, 0.0067, 0.0444],\n",
       "         [0.9932, 0.0169, 0.0118, 0.0074],\n",
       "         [0.9908, 0.0203, 0.0089, 0.0086],\n",
       "         [0.0114, 0.9870, 0.0060, 0.0105],\n",
       "         [0.9942, 0.0201, 0.0096, 0.0101],\n",
       "         [0.0085, 0.9850, 0.0029, 0.0151],\n",
       "         [0.0085, 0.9810, 0.0034, 0.0105],\n",
       "         [0.0052, 0.9844, 0.0058, 0.0094],\n",
       "         [0.0130, 0.9765, 0.0205, 0.0113],\n",
       "         [0.9942, 0.0184, 0.0093, 0.0094],\n",
       "         [0.0144, 0.9780, 0.0056, 0.0133],\n",
       "         [0.0059, 0.9884, 0.0041, 0.0089],\n",
       "         [0.1801, 0.0174, 0.9541, 0.0108]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.21it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "submission_ID = []\n",
    "with torch.no_grad():\n",
    "    for index, dataset in tqdm(enumerate(test_prod_data_loader), total = len(test_prod_data_loader)):\n",
    "        sub_id = dataset['sub_id']\n",
    "        ids = dataset['ids'].to(device)\n",
    "        #token_type_ids = dataset['token_type_ids'].to(device)\n",
    "        mask = dataset['mask'].to(device)\n",
    "\n",
    "        output = model(input_ids = ids,\n",
    "                       #token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask)\n",
    "        \n",
    "        submission_ID.extend(sub_id)\n",
    "        predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())\n",
    "    predicted_output = np.array(predicted_output)\n",
    "            \n",
    "        #predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.011118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.987378</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.009145</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.987523</td>\n",
       "      <td>0.007561</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.004713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>0.983092</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.012617</td>\n",
       "      <td>0.002972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.386111</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.682546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Z9A6ACLK</td>\n",
       "      <td>0.918719</td>\n",
       "      <td>0.023373</td>\n",
       "      <td>0.011878</td>\n",
       "      <td>0.009388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ZDUOIGKN</td>\n",
       "      <td>0.626443</td>\n",
       "      <td>0.073533</td>\n",
       "      <td>0.152156</td>\n",
       "      <td>0.025714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ZHQ60CCH</td>\n",
       "      <td>0.438941</td>\n",
       "      <td>0.273319</td>\n",
       "      <td>0.232021</td>\n",
       "      <td>0.066414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ZVIJMA4O</td>\n",
       "      <td>0.022413</td>\n",
       "      <td>0.058782</td>\n",
       "      <td>0.014278</td>\n",
       "      <td>0.955454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ZYIFAY98</td>\n",
       "      <td>0.557877</td>\n",
       "      <td>0.212203</td>\n",
       "      <td>0.102656</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Depression   Alcohol   Suicide     Drugs\n",
       "0    02V56KMO    0.931522  0.024450  0.038067  0.011118\n",
       "1    03BMGTOK    0.987378  0.005538  0.009145  0.004602\n",
       "2    03LZVFM6    0.987523  0.007561  0.008126  0.004713\n",
       "3    0EPULUM5    0.983092  0.006485  0.012617  0.002972\n",
       "4    0GM4C5GD    0.014191  0.386111  0.008929  0.682546\n",
       "..        ...         ...       ...       ...       ...\n",
       "304  Z9A6ACLK    0.918719  0.023373  0.011878  0.009388\n",
       "305  ZDUOIGKN    0.626443  0.073533  0.152156  0.025714\n",
       "306  ZHQ60CCH    0.438941  0.273319  0.232021  0.066414\n",
       "307  ZVIJMA4O    0.022413  0.058782  0.014278  0.955454\n",
       "308  ZYIFAY98    0.557877  0.212203  0.102656  0.035717\n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.DataFrame(predicted_output)\n",
    "final_output.columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "final_output['ID'] = submission_ID\n",
    "\n",
    "final_output = final_output[['ID', 'Depression', 'Alcohol', 'Suicide', 'Drugs']]\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('../output/sub_Roberta_26.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
