{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/thanish/Competition/Zindi/Tech4MentalHealth/Notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "\n",
    "\n",
    "import tokenizers\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os \n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'train_path' : '../data/train_corrected.csv',\n",
    "          'test_path' : '../data/test_corrected.csv',\n",
    "          'train_batch_size' : 8,\n",
    "          'valid_batch_size' : 8,\n",
    "          'test_batch_size' : 64,\n",
    "          'MAX_LEN' : 196,\n",
    "          'EPOCH' : 3, \n",
    "          'BERT_PATH_laptop': 'C:/Users/thanisb/Documents/bert_large_uncased',\n",
    "          'BERT_PATH_desktop': '/home/thanish/Competition/bert_large_uncased',\n",
    "          'BERT_PATH_Azure': '/home/thanish/transformer_models/bert_large_uncased'\n",
    "          }\n",
    "\n",
    "TOKENIZER = transformers.BertTokenizer(os.path.join(config['BERT_PATH_Azure'], 'vocab.txt'),lowercase = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                               text       label\n",
       "0  SUAVK39Z            i feel that it was better i dream happy  Depression\n",
       "1  9JDAGUV3                        why do i get hallucinations       Drugs\n",
       "2  419WR1LQ  i am stressed due to lack of financial support...  Depression\n",
       "3  6UY7DX6Q                              why is life important     Suicide\n",
       "4  FYC0FTFB  how could i be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_DF = pd.read_csv(config['train_path'])\n",
    "test_DF = pd.read_csv(config['test_path'])\n",
    "\n",
    "train_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Suicide</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SUAVK39Z</td>\n",
       "      <td>i feel that it was better i dream happy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9JDAGUV3</td>\n",
       "      <td>why do i get hallucinations</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>419WR1LQ</td>\n",
       "      <td>i am stressed due to lack of financial support...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6UY7DX6Q</td>\n",
       "      <td>why is life important</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FYC0FTFB</td>\n",
       "      <td>how could i be helped to go through the depres...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>BOHSNXCN</td>\n",
       "      <td>what should i do to stop alcoholism</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>GVDXRQPY</td>\n",
       "      <td>how to become my oneself again</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>IO4JHIQS</td>\n",
       "      <td>how can someone stop it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1DS3P1XO</td>\n",
       "      <td>i feel unworthy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>ORF71PVQ</td>\n",
       "      <td>i feel so discouraged with life</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>616 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID                                               text  Alcohol  \\\n",
       "0    SUAVK39Z            i feel that it was better i dream happy        0   \n",
       "1    9JDAGUV3                        why do i get hallucinations        0   \n",
       "2    419WR1LQ  i am stressed due to lack of financial support...        0   \n",
       "3    6UY7DX6Q                              why is life important        0   \n",
       "4    FYC0FTFB  how could i be helped to go through the depres...        0   \n",
       "..        ...                                                ...      ...   \n",
       "611  BOHSNXCN                what should i do to stop alcoholism        1   \n",
       "612  GVDXRQPY                     how to become my oneself again        0   \n",
       "613  IO4JHIQS                            how can someone stop it        1   \n",
       "614  1DS3P1XO                                    i feel unworthy        0   \n",
       "615  ORF71PVQ                    i feel so discouraged with life        0   \n",
       "\n",
       "     Depression  Drugs  Suicide  \n",
       "0             1      0        0  \n",
       "1             0      1        0  \n",
       "2             1      0        0  \n",
       "3             0      0        1  \n",
       "4             1      0        0  \n",
       "..          ...    ...      ...  \n",
       "611           0      0        0  \n",
       "612           0      0        1  \n",
       "613           0      0        0  \n",
       "614           1      0        0  \n",
       "615           1      0        0  \n",
       "\n",
       "[616 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the label to OHE\n",
    "train_DF = pd.concat([train_DF[['ID', 'text']], pd.get_dummies(train_DF.label)], axis = 1)\n",
    "train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(492, 6) (124, 6)\n"
     ]
    }
   ],
   "source": [
    "# Splitting the data to train and validation\n",
    "np.random.seed(100)\n",
    "train_local, valid_local = train_test_split(train_DF,\n",
    "                                            test_size = 0.2,\n",
    "                                            random_state = 100)\n",
    "\n",
    "train_local = train_local.reset_index(drop = True)\n",
    "valid_local = valid_local.reset_index(drop = True)\n",
    "\n",
    "print(train_local.shape, valid_local.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class if for converting the data to be accepted by the BERT model\n",
    "class form_input():\n",
    "    \n",
    "    def __init__(self, text_id, text, label, data_type = 'test'):\n",
    "        self.data_type = data_type\n",
    "        self.text_id = text_id\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.max_len = config['MAX_LEN']\n",
    "        self.tokenizer = TOKENIZER\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        inputs =  TOKENIZER.encode_plus(self.text[item])\n",
    "        \n",
    "        sub_id = self.text_id[item]\n",
    "        ids = inputs['input_ids']\n",
    "        tok_type_id = inputs['token_type_ids']\n",
    "        att_mask = inputs['attention_mask']\n",
    "        pad_len = self.max_len - len(ids)\n",
    "\n",
    "        ids = ids + [0]*pad_len\n",
    "        tok_type_id = tok_type_id + [0]*pad_len\n",
    "        att_mask = att_mask + [0]*pad_len\n",
    "        \n",
    "        if self.data_type != 'test':\n",
    "            label = self.label[item]\n",
    "        else:\n",
    "            label = 1\n",
    "        \n",
    "        return {'sub_id': sub_id,\n",
    "                #'Actual_text': self.text[item],\n",
    "                'ids': torch.tensor(ids, dtype = torch.long),\n",
    "                'mask': torch.tensor(att_mask, dtype = torch.long),\n",
    "                'token_type_ids': torch.tensor(tok_type_id, dtype = torch.long),\n",
    "                'targets': torch.tensor(label, dtype = torch.long)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sub_id': 'BOHSNXCN',\n",
       " 'ids': tensor([ 101, 1184, 1431,  178, 1202, 1106, 1831, 6272, 1863,  102,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0,    0,    0]),\n",
       " 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]),\n",
       " 'targets': tensor([1, 0, 0, 0])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "\n",
    "train_local_data = form_input(train_local.ID, train_local.text, train_local[lab_columns].values, 'train')\n",
    "valid_local_data = form_input(valid_local.ID, valid_local.text, valid_local[lab_columns].values, 'train')\n",
    "train_prod_data = form_input(train_DF.ID, train_DF.text, train_DF[lab_columns].values, 'train')\n",
    "test_prod_data = form_input(test_DF.ID, test_DF.text, None, 'test')\n",
    "\n",
    "train_local_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data loader function to pass the input in batces\n",
    "\n",
    "train_local_data_loader = DataLoader(train_local_data, \n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(train_local_data),\n",
    "                                     batch_size=config['train_batch_size'])\n",
    "valid_local_data_loader = DataLoader(valid_local_data,\n",
    "                                     #shuffle=True,\n",
    "                                     sampler = RandomSampler(valid_local_data),\n",
    "                                     batch_size=config['valid_batch_size'])\n",
    "\n",
    "train_prod_data_loader = DataLoader(train_prod_data, \n",
    "                                    #shuffle=True,\n",
    "                                    sampler = RandomSampler(train_prod_data),\n",
    "                                    batch_size=config['train_batch_size'])\n",
    "\n",
    "test_prod_data_loader = DataLoader(test_prod_data,\n",
    "                                   #shuffle=False,\n",
    "                                   sampler = SequentialSampler(test_prod_data),\n",
    "                                   batch_size=config['test_batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTMultiLabelSequenceClassification(torch.nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(BERTMultiLabelSequenceClassification, self).__init__()\n",
    "        self.freeze_bert = True\n",
    "        self.num_labels = num_labels\n",
    "        self.Bert_large = transformers.BertModel.from_pretrained(config['BERT_PATH_Azure'])\n",
    "        self.classifier = torch.nn.Linear(1024, self.num_labels)\n",
    "        \n",
    "        freez_parm = ['classifier', \n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11',\n",
    "                      '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']\n",
    "        if self.freeze_bert:\n",
    "            # for param in self.Bert_large.parameters():\n",
    "            for n, param in self.Bert_large.named_parameters():\n",
    "                if not any(nd in n for nd in freez_parm):\n",
    "                    param.requires_grad = False\n",
    "                \n",
    "    def pool_hidden_state(self, last_hidden_state):\n",
    "        \"Pool the hidden output into a single mean vector\"\n",
    "        last_hidden_state = last_hidden_state[0]\n",
    "        mean_last_hidden_state = torch.mean(last_hidden_state, 1)\n",
    "        return mean_last_hidden_state\n",
    "        \n",
    "    def forward(self, input_ids, token_type_ids = None, attention_mask = None, labels = None):\n",
    "        # Last layer\n",
    "        last_hidden_state = self.Bert_large(input_ids = input_ids, \n",
    "                                            token_type_ids = token_type_ids,\n",
    "                                            attention_mask = attention_mask\n",
    "                                       )\n",
    "        # Pooled the outputs in a mean vector\n",
    "        mean_last_hidden_state = self.pool_hidden_state(last_hidden_state)\n",
    "        logits = self.classifier(mean_last_hidden_state)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_fct = nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.view(-1, self.num_labels))\n",
    "            return loss, logits\n",
    "        else:\n",
    "            return logits\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setting_seed(seed_no):\n",
    "    random.seed(seed_no)\n",
    "    np.random.seed(seed_no)\n",
    "    torch.manual_seed(seed_no)\n",
    "    torch.cuda.manual_seed_all(seed_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_2_tune(model):\n",
    "    FULL_FINETUNING = True\n",
    "    if FULL_FINETUNING:\n",
    "        param_optimizer = list(model.named_parameters())\n",
    "        no_decay = ['bias', 'gamma', 'beta']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.01},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "    else:\n",
    "        param_optimizer = list(model.named_parameters()) \n",
    "        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "    return optimizer_grouped_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(data_loader, model, optimizer, scheduler, params):\n",
    "    \n",
    "    model.train()\n",
    "    setting_seed(seed_no = seed)\n",
    "    \n",
    "    train_loss  = 0\n",
    "    for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "        ids = dataset['ids'].to(device, dtype = torch.long)\n",
    "        mask = dataset['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = dataset['token_type_ids'].to(device, dtype = torch.long)\n",
    "        target = dataset['targets'].to(device, dtype = torch.float)\n",
    "    \n",
    "        output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "        \n",
    "        step_loss = output[0]\n",
    "         \n",
    "        step_loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        train_loss += step_loss\n",
    "        \n",
    "    print('Saving the model')\n",
    "    torch.save(model, '../output/best_Bert_large_model.bin')\n",
    "    \n",
    "    print(\"Avg Train loss\" , (train_loss/len(data_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_fn(data_loader, model):\n",
    "    \n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    actual_output = []\n",
    "    predicted_output = []\n",
    "    with torch.no_grad():\n",
    "        for index, dataset in tqdm(enumerate(data_loader), total = len(data_loader)):\n",
    "            ids = dataset['ids'].to(device)\n",
    "            token_type_ids = dataset['token_type_ids'].to(device)\n",
    "            mask = dataset['mask'].to(device)\n",
    "            target = dataset['targets'].to(device, dtype = torch.float)\n",
    "            \n",
    "            output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask,\n",
    "                       labels = target\n",
    "                      )\n",
    "            \n",
    "            step_loss = output[0]\n",
    "            prediction = output[1]\n",
    "            \n",
    "            eval_loss += step_loss\n",
    "            \n",
    "            actual_output.extend(target.detach().cpu().numpy().tolist())\n",
    "            predicted_output.extend(prediction.detach().cpu().numpy().tolist())\n",
    "        \n",
    "        print(\"Avg Eval loss\" , (eval_loss/len(data_loader)))\n",
    "        \n",
    "        return actual_output, predicted_output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def training_engine(epoc, train_data):\n",
    "       \n",
    "    setting_seed(seed_no = seed)\n",
    "    model = BERTMultiLabelSequenceClassification(num_labels = len(lab_columns))\n",
    "    model = nn.DataParallel(model)\n",
    "    model.to(device)\n",
    "    \n",
    "    optimizer_grouped_parameters = params_2_tune(model)\n",
    "    optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr = 5e-5)\n",
    "    \n",
    "    EPOCHS = epoc\n",
    "    total_steps = len(train_data) * EPOCHS\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = transformers.get_linear_schedule_with_warmup(optimizer,\n",
    "                                                             num_warmup_steps=0, # Default value\n",
    "                                                             num_training_steps=total_steps)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_fn(data_loader = train_data,\n",
    "                 model = model,\n",
    "                 optimizer = optimizer, \n",
    "                 scheduler = scheduler, \n",
    "                 params = optimizer_grouped_parameters)\n",
    "\n",
    "        # Evaluation\n",
    "        actual, predicted = eval_fn(data_loader = valid_local_data_loader,\n",
    "                                    model = model)\n",
    "\n",
    "        actual = np.array(actual)\n",
    "        #predicted_prob = np.array(predicted)\n",
    "        predicted_prob = predicted\n",
    "        predicted_class = np.argmax(np.array(predicted), axis = 1)\n",
    "\n",
    "    #    acc = accuracy_score(actual, predicted_class)\n",
    "        log_ls = log_loss(actual, torch.tensor(predicted_prob).sigmoid())    \n",
    "\n",
    "    #    print(\"Epoch {}/{} Eval Accuracy: {}, Logloss: {}\".format(epoch, EPOCHS, acc, log_ls))\n",
    "        print(\"Epoch {}/{} Logloss: {}\".format(epoch, EPOCHS, log_ls))\n",
    "    return model, actual, predicted_prob, predicted_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training on the Local dataset\n",
    "\n",
    "seed = 50\n",
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 5, train_data = train_local_data_loader)\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [02:03<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.2562, 0.2772], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.75it/s]\n",
      "  0%|          | 0/77 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.0978, 0.0798], device='cuda:0')\n",
      "Epoch 0/2 Logloss: 0.21130635828200367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 77/77 [02:02<00:00,  1.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Train loss tensor([0.0776, 0.0693], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:09<00:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Eval loss tensor([0.0524, 0.0233], device='cuda:0')\n",
      "Epoch 1/2 Logloss: 0.09365157332391508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.]]),\n",
       " array([0, 1, 1, 1, 2, 1, 3, 1, 1, 3, 0, 0, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1,\n",
       "        1, 0, 2, 1, 2, 0, 1, 0, 1, 0, 0, 1, 1, 3, 2, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 3, 0, 3, 1, 3, 1, 2, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1,\n",
       "        0, 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1,\n",
       "        1, 1, 1, 1, 0, 3, 1, 1, 0, 2, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 3,\n",
       "        1, 0, 0, 3, 1, 0, 1, 0, 1, 3, 1, 0, 1, 0]),\n",
       " tensor([[0.9954, 0.0061, 0.0028, 0.0081],\n",
       "         [0.0036, 0.9931, 0.0049, 0.0079],\n",
       "         [0.0026, 0.9934, 0.0052, 0.0122],\n",
       "         [0.0033, 0.9937, 0.0043, 0.0090],\n",
       "         [0.0184, 0.0187, 0.9757, 0.0324],\n",
       "         [0.0034, 0.9927, 0.0045, 0.0107],\n",
       "         [0.0271, 0.0143, 0.0326, 0.9888],\n",
       "         [0.0036, 0.9926, 0.0059, 0.0085],\n",
       "         [0.0045, 0.9930, 0.0054, 0.0056],\n",
       "         [0.0752, 0.2050, 0.0163, 0.8655],\n",
       "         [0.9950, 0.0049, 0.0037, 0.0079],\n",
       "         [0.9953, 0.0056, 0.0030, 0.0084],\n",
       "         [0.0060, 0.9810, 0.0085, 0.0208],\n",
       "         [0.0033, 0.9934, 0.0055, 0.0092],\n",
       "         [0.0036, 0.9948, 0.0062, 0.0051],\n",
       "         [0.0093, 0.9581, 0.0030, 0.0725],\n",
       "         [0.0354, 0.0155, 0.0338, 0.9867],\n",
       "         [0.0037, 0.9925, 0.0044, 0.0078],\n",
       "         [0.0199, 0.0222, 0.9778, 0.0369],\n",
       "         [0.0264, 0.0152, 0.9729, 0.0397],\n",
       "         [0.0046, 0.9934, 0.0079, 0.0050],\n",
       "         [0.0048, 0.9930, 0.0066, 0.0059],\n",
       "         [0.0287, 0.9333, 0.0078, 0.0482],\n",
       "         [0.9922, 0.0043, 0.0062, 0.0067],\n",
       "         [0.0162, 0.0187, 0.9772, 0.0310],\n",
       "         [0.0045, 0.9852, 0.0049, 0.0205],\n",
       "         [0.0117, 0.0280, 0.9783, 0.0327],\n",
       "         [0.9953, 0.0060, 0.0029, 0.0088],\n",
       "         [0.0064, 0.9790, 0.0044, 0.0278],\n",
       "         [0.9948, 0.0054, 0.0031, 0.0072],\n",
       "         [0.0052, 0.9916, 0.0069, 0.0105],\n",
       "         [0.9949, 0.0055, 0.0031, 0.0069],\n",
       "         [0.9935, 0.0081, 0.0060, 0.0090],\n",
       "         [0.0080, 0.9905, 0.0065, 0.0135],\n",
       "         [0.0037, 0.9933, 0.0038, 0.0094],\n",
       "         [0.1644, 0.1104, 0.0237, 0.8310],\n",
       "         [0.0298, 0.0140, 0.9773, 0.0184],\n",
       "         [0.0052, 0.9888, 0.0040, 0.0223],\n",
       "         [0.9953, 0.0057, 0.0032, 0.0083],\n",
       "         [0.0044, 0.9940, 0.0061, 0.0050],\n",
       "         [0.0062, 0.9862, 0.0044, 0.0165],\n",
       "         [0.0065, 0.9935, 0.0060, 0.0091],\n",
       "         [0.0131, 0.9295, 0.0046, 0.1067],\n",
       "         [0.0034, 0.9941, 0.0052, 0.0058],\n",
       "         [0.9948, 0.0052, 0.0032, 0.0091],\n",
       "         [0.0063, 0.9860, 0.0066, 0.0164],\n",
       "         [0.0035, 0.9942, 0.0048, 0.0064],\n",
       "         [0.0049, 0.9923, 0.0067, 0.0053],\n",
       "         [0.0042, 0.9737, 0.0139, 0.0076],\n",
       "         [0.0959, 0.0553, 0.0251, 0.9498],\n",
       "         [0.9955, 0.0048, 0.0033, 0.0083],\n",
       "         [0.2468, 0.0309, 0.1294, 0.6360],\n",
       "         [0.0032, 0.9901, 0.0031, 0.0165],\n",
       "         [0.0770, 0.1336, 0.0137, 0.8734],\n",
       "         [0.0310, 0.6765, 0.0076, 0.2153],\n",
       "         [0.0209, 0.0139, 0.9827, 0.0239],\n",
       "         [0.0376, 0.0430, 0.9100, 0.0915],\n",
       "         [0.0041, 0.9875, 0.0060, 0.0096],\n",
       "         [0.0279, 0.0198, 0.0252, 0.9872],\n",
       "         [0.0048, 0.9940, 0.0052, 0.0088],\n",
       "         [0.0036, 0.9945, 0.0056, 0.0047],\n",
       "         [0.0036, 0.9883, 0.0062, 0.0155],\n",
       "         [0.0366, 0.2987, 0.0084, 0.8191],\n",
       "         [0.0036, 0.9920, 0.0054, 0.0084],\n",
       "         [0.0065, 0.9650, 0.0033, 0.0767],\n",
       "         [0.0046, 0.9939, 0.0080, 0.0050],\n",
       "         [0.9922, 0.0043, 0.0062, 0.0067],\n",
       "         [0.0318, 0.0167, 0.0304, 0.9895],\n",
       "         [0.0185, 0.0149, 0.9756, 0.0322],\n",
       "         [0.0047, 0.9914, 0.0059, 0.0059],\n",
       "         [0.0044, 0.9941, 0.0040, 0.0089],\n",
       "         [0.0032, 0.9922, 0.0045, 0.0103],\n",
       "         [0.0036, 0.9931, 0.0049, 0.0079],\n",
       "         [0.0041, 0.9911, 0.0049, 0.0127],\n",
       "         [0.1083, 0.2023, 0.0365, 0.8101],\n",
       "         [0.0034, 0.9935, 0.0051, 0.0076],\n",
       "         [0.0068, 0.9850, 0.0045, 0.0198],\n",
       "         [0.9848, 0.0043, 0.0156, 0.0063],\n",
       "         [0.9956, 0.0051, 0.0034, 0.0089],\n",
       "         [0.0051, 0.9926, 0.0053, 0.0073],\n",
       "         [0.0149, 0.8377, 0.0095, 0.0685],\n",
       "         [0.9869, 0.0044, 0.0156, 0.0074],\n",
       "         [0.0146, 0.9707, 0.0041, 0.0286],\n",
       "         [0.0082, 0.9837, 0.0042, 0.0211],\n",
       "         [0.8388, 0.0051, 0.1749, 0.0096],\n",
       "         [0.0363, 0.8573, 0.0077, 0.1451],\n",
       "         [0.0274, 0.0113, 0.9766, 0.0312],\n",
       "         [0.0051, 0.9941, 0.0063, 0.0066],\n",
       "         [0.0034, 0.9950, 0.0051, 0.0064],\n",
       "         [0.0074, 0.9847, 0.0055, 0.0162],\n",
       "         [0.0048, 0.9917, 0.0031, 0.0099],\n",
       "         [0.0036, 0.9925, 0.0043, 0.0092],\n",
       "         [0.9848, 0.0072, 0.0116, 0.0066],\n",
       "         [0.0722, 0.1723, 0.0142, 0.8649],\n",
       "         [0.0046, 0.9939, 0.0080, 0.0050],\n",
       "         [0.0036, 0.9941, 0.0041, 0.0068],\n",
       "         [0.9947, 0.0050, 0.0036, 0.0076],\n",
       "         [0.0388, 0.0134, 0.9719, 0.0260],\n",
       "         [0.9952, 0.0056, 0.0032, 0.0080],\n",
       "         [0.0047, 0.9943, 0.0060, 0.0085],\n",
       "         [0.0041, 0.9937, 0.0064, 0.0058],\n",
       "         [0.9724, 0.0063, 0.0288, 0.0050],\n",
       "         [0.0046, 0.9941, 0.0075, 0.0060],\n",
       "         [0.0058, 0.9884, 0.0066, 0.0096],\n",
       "         [0.9938, 0.0072, 0.0051, 0.0109],\n",
       "         [0.0413, 0.6759, 0.0068, 0.4865],\n",
       "         [0.0054, 0.9902, 0.0035, 0.0089],\n",
       "         [0.0045, 0.9929, 0.0054, 0.0058],\n",
       "         [0.0046, 0.9946, 0.0073, 0.0059],\n",
       "         [0.0985, 0.1655, 0.0109, 0.8580],\n",
       "         [0.0051, 0.9871, 0.0067, 0.0168],\n",
       "         [0.9955, 0.0058, 0.0030, 0.0075],\n",
       "         [0.9945, 0.0072, 0.0044, 0.0101],\n",
       "         [0.1278, 0.0908, 0.0668, 0.6669],\n",
       "         [0.0049, 0.9944, 0.0067, 0.0047],\n",
       "         [0.9953, 0.0062, 0.0030, 0.0091],\n",
       "         [0.0223, 0.8785, 0.0044, 0.0636],\n",
       "         [0.9953, 0.0056, 0.0029, 0.0078],\n",
       "         [0.0050, 0.9922, 0.0048, 0.0120],\n",
       "         [0.1111, 0.0495, 0.0447, 0.9166],\n",
       "         [0.0034, 0.9898, 0.0054, 0.0199],\n",
       "         [0.9955, 0.0062, 0.0029, 0.0083],\n",
       "         [0.0051, 0.9942, 0.0069, 0.0049],\n",
       "         [0.9956, 0.0059, 0.0030, 0.0084]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training on the Overall dataset\n",
    "seed = 50\n",
    "model, actual, predicted_prob, predicted_class = training_engine(epoc = 2, train_data = train_prod_data_loader)\n",
    "actual, predicted_class, torch.tensor(predicted_prob).sigmoid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "actual_output = []\n",
    "predicted_output = []\n",
    "\n",
    "submission_ID = []\n",
    "with torch.no_grad():\n",
    "    for index, dataset in tqdm(enumerate(test_prod_data_loader), total = len(test_prod_data_loader)):\n",
    "        sub_id = dataset['sub_id']\n",
    "        ids = dataset['ids'].to(device)\n",
    "        token_type_ids = dataset['token_type_ids'].to(device)\n",
    "        mask = dataset['mask'].to(device)\n",
    "\n",
    "        output = model(input_ids = ids,\n",
    "                       token_type_ids = token_type_ids,\n",
    "                       attention_mask = mask)\n",
    "        \n",
    "        submission_ID.extend(sub_id)\n",
    "        predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())\n",
    "    predicted_output = np.array(predicted_output)\n",
    "            \n",
    "        #predicted_output.extend(output.sigmoid().detach().cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Suicide</th>\n",
       "      <th>Drugs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02V56KMO</td>\n",
       "      <td>0.617146</td>\n",
       "      <td>0.039451</td>\n",
       "      <td>0.300991</td>\n",
       "      <td>0.004501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03BMGTOK</td>\n",
       "      <td>0.993702</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.004644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03LZVFM6</td>\n",
       "      <td>0.994396</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.005875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0EPULUM5</td>\n",
       "      <td>0.992825</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.010829</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0GM4C5GD</td>\n",
       "      <td>0.008356</td>\n",
       "      <td>0.639821</td>\n",
       "      <td>0.007597</td>\n",
       "      <td>0.333977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Z9A6ACLK</td>\n",
       "      <td>0.862103</td>\n",
       "      <td>0.032368</td>\n",
       "      <td>0.079699</td>\n",
       "      <td>0.012119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>ZDUOIGKN</td>\n",
       "      <td>0.981647</td>\n",
       "      <td>0.007022</td>\n",
       "      <td>0.034433</td>\n",
       "      <td>0.005938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>ZHQ60CCH</td>\n",
       "      <td>0.496715</td>\n",
       "      <td>0.093610</td>\n",
       "      <td>0.356248</td>\n",
       "      <td>0.013090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>ZVIJMA4O</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>0.023232</td>\n",
       "      <td>0.971566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>ZYIFAY98</td>\n",
       "      <td>0.117858</td>\n",
       "      <td>0.282763</td>\n",
       "      <td>0.385523</td>\n",
       "      <td>0.041308</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  Depression   Alcohol   Suicide     Drugs\n",
       "0    02V56KMO    0.617146  0.039451  0.300991  0.004501\n",
       "1    03BMGTOK    0.993702  0.002767  0.011647  0.004644\n",
       "2    03LZVFM6    0.994396  0.004023  0.004961  0.005875\n",
       "3    0EPULUM5    0.992825  0.003201  0.010829  0.004295\n",
       "4    0GM4C5GD    0.008356  0.639821  0.007597  0.333977\n",
       "..        ...         ...       ...       ...       ...\n",
       "304  Z9A6ACLK    0.862103  0.032368  0.079699  0.012119\n",
       "305  ZDUOIGKN    0.981647  0.007022  0.034433  0.005938\n",
       "306  ZHQ60CCH    0.496715  0.093610  0.356248  0.013090\n",
       "307  ZVIJMA4O    0.012416  0.034166  0.023232  0.971566\n",
       "308  ZYIFAY98    0.117858  0.282763  0.385523  0.041308\n",
       "\n",
       "[309 rows x 5 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = pd.DataFrame(predicted_output)\n",
    "final_output.columns = ['Alcohol', 'Depression', 'Drugs', 'Suicide']\n",
    "final_output['ID'] = submission_ID\n",
    "\n",
    "final_output = final_output[['ID', 'Depression', 'Alcohol', 'Suicide', 'Drugs']]\n",
    "final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output.to_csv('../output/sub_46_Bert_Large.csv', index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
